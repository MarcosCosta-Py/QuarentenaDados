{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuarentenaDados_Desafio-Final_(Alura)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4tN9zBfTiNtdgyAy3M/c3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcosCosta-Py/QuarentenaDados/blob/master/QuarentenaDados_Desafio_Final_(Alura).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLoZHfXEDjCl",
        "colab_type": "text"
      },
      "source": [
        "# Desafio #QuarentenaDados\n",
        "\n",
        "Bem-vinda e bem-vindo ao desafio #QuarentenaDados.\n",
        "\n",
        "Esse notebook traz informações dos dados e como você deve configurar seu arquivo final para submissão.\n",
        "\n",
        "**Caso queira usar esse notebook como exemplo para desenvolver seu projeto, clique em file e escolha a opção Save a copy in Drive**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExrD0wyRDkbn",
        "colab_type": "text"
      },
      "source": [
        "Vamos trabalhar com uma amostra aleatória da base de dados MICRODADOS ENEM 2018, essa amostra é **diferente da apresentada em aula**. Junto com a divulgação do resultado final estaremos disponibilizando o código que gerou os dados para que você possa analisar e reproduzir os datasets. \n",
        "\n",
        "Seu objetivo é prever da melhor forma possível a nota das provas de **linguagens e códigos** (NU_NOTA_LC), dado todas as outras notas. O modelo que tiver o menor **erro quadrático médio (MSE)** vence o desafio.\n",
        "\n",
        "Para o desafio você tem três bases à disposição, duas para desenvolver seu modelo e uma para submissão da predição. As bases são as seguintes:\n",
        "\n",
        "- **dados_treino**: São 1500000 linhas contendo a nota das 4 provas + nota de redação.\n",
        "\n",
        "- **dados_teste**: São 20000 linhas contendo com notas das 4 provas + nota de redação.\n",
        "\n",
        "- **dados_desafioqt**: São 10000 linhas com nota de 3 provas + nota de redação. A nota da prova de **Linguagem e Codigos** (NU_NOTA_LC) não está disponível nessa base.\n",
        "\n",
        "\n",
        "As base **dados_treino e dados_teste**, contém as seguintes colunas; **NU_NOTA_CN, NU_NOTA_CH, NU_NOTA_MT, NU_NOTA_REDACAO, NU_NOTA_LC** (Você pode consultar a aula 5, onde o Guilherme explica o significado das siglas). A coluna que você deve realizar a **previsão** é **NU_NOTA_LC**. Você pode manipular os dados da forma que quiser, o importante é que no final submeta o arquivo com as informações corretas (detalhes da submissão serão discutidos no final deste notebook).\n",
        "\n",
        "A base **dados_desafioqt**, contém as seguintes colunas; **ID, NU_NOTA_CN, NU_NOTA_CH, NU_NOTA_MT, NU_NOTA_REDACAO**. Repare que os dados **NU_NOTA_LC** não estão presentes, essa é justamente a informação que você precisa prever. Nós temos os valores reais das notas, no final do prazo de submissão um script irá avaliar sua previsão e dará uma nota para o seu modelo. Nessa base também temos o **ID**, essa informação é importante para o envio da sua previsão, garanta que a nota prevista corresponda ao respectivo **ID**.\n",
        "\n",
        "Se você está habituado com o desenvolvimento de modelos de ML, repare que essa divisão de dados é exatamente a mesma que Treino, Teste e Validação. \n",
        "\n",
        "Abaixo preparamos um código exemplo para você seguir, sinta-se à vontade para experimentar diversos outros métodos, mas **GARANTA QUE O ARQUIVO DE SUBMISSÃO ESTEJA CONFIGURADO CORRETAMENTE**.\n",
        "\n",
        "Na primeira parte, estamos lendo a base de dados direto de arquivos no github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6NY-9ZLFTFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "URI_TREINO = \"https://github.com/tgcsantos/quaretenadados/blob/master/DADOS_TREINO.csv?raw=true\"\n",
        "URI_TESTE = \"https://github.com/tgcsantos/quaretenadados/raw/master/DADOS_TESTE.csv\"\n",
        "URI_DESAFIOQT = \"https://github.com/tgcsantos/quaretenadados/raw/master/DESAFIOQT.csv\"\n",
        "\n",
        "dados_treino = pd.read_csv(URI_TREINO)\n",
        "dados_teste = pd.read_csv(URI_TESTE)\n",
        "dados_desafioqt = pd.read_csv(URI_DESAFIOQT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0feEGU4EP9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "erro_treino = \"Erro ao carregar dados de treino\"\n",
        "erro_teste = \"Erro ao carregar dados de teste\"\n",
        "erro_desafioqt = \"Erro ao carregar dados de submissão\"\n",
        "\n",
        "assert dados_treino.shape == (150000, 5), erro_treino\n",
        "assert dados_teste.shape == (20000, 5), erro_teste\n",
        "assert dados_desafioqt.shape == (10000, 5), erro_desafioqt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhjUt50XEssD",
        "colab_type": "text"
      },
      "source": [
        "Agora com as bases de dados lidas, vamos separar as informações de cada dataset. X_treino e Y_treino são as **features**, X_teste e Y_teste são as **labels** a serem previstas.\n",
        "\n",
        "Duas observações nesta parte:\n",
        "\n",
        "- 1° Como já disponibilizamos os dados de treino e teste separados, você não precisa fazer *train_test_split* feito em aula (porém fique à vontade para trabalhar da forma que achar melhor).\n",
        "\n",
        "- 2° Transformamos X_treino, Y_treino, X_teste, Y_teste em arrays numpy. Se você quiser usar uma biblioteca que não aceite dataframe como entrada de dados, já deixamos pronto para você."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aEIp1WUT4_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coluna_label = 'NU_NOTA_LC'\n",
        "coluna_features = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']\n",
        "\n",
        "X_treino = dados_treino[coluna_features].to_numpy()\n",
        "Y_treino = dados_treino[coluna_label].to_numpy()\n",
        "X_teste = dados_teste[coluna_features].to_numpy()\n",
        "Y_teste = dados_teste[coluna_label].to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouwzy1TfIwxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No comando abaixo juntaremos os datasets de treino e teste para uma nova separação dos dados.\n",
        "relacao_colunas = {'NU_NOTA_CN':'NU_NOTA_CN',\t'NU_NOTA_CH':'NU_NOTA_CH'\t,'NU_NOTA_LC':'NU_NOTA_LC',\t'NU_NOTA_MT':'NU_NOTA_MT','NU_NOTA_REDACAO':'NU_NOTA_REDACAO'}\n",
        "df_total = pd.concat([dados_treino, dados_teste.rename(columns=relacao_colunas)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeZIZVazGnZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agora iremos separar as colunas referentes as variáveis que temos(X) e a variável que queremos prever(y).\n",
        "X_total = df_total[['NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_MT','NU_NOTA_REDACAO']]\n",
        "y_total = df_total['NU_NOTA_LC']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd74UgmcGbxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando um método para separação dos dados.\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtRXu4pfMqFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando a métrica erro quadrático médio (MSE) para verificar a precisão do modelo.\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ekEt4V9Gbfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dividindo o conjunto de dados.\n",
        "import numpy as np\n",
        "np.random.seed(4225)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_total,y_total,test_size=0.21,random_state=(240))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-s7EYtXL9HI",
        "colab_type": "text"
      },
      "source": [
        "Com os novos conjuntos de dados prontos, iremos aplicá-los em quatro modelos de Machine Learning distintos para verificar qual deles apresentam o melhor resultado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2SAIf0tMaUZ",
        "colab_type": "code",
        "outputId": "f9193204-3c9d-4700-8120-6d08101ec1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Aplicando o modelo de Regressão Linear\n",
        "from sklearn.linear_model import LinearRegression\n",
        "modelo_lr = LinearRegression()\n",
        "modelo_lr.fit(X_train,y_train)\n",
        "pred_lr = modelo_lr.predict(X_test)\n",
        "print(mean_squared_error(y_test,pred_lr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2123.5300794621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g82C34dKtbdf",
        "colab_type": "code",
        "outputId": "4fa637f4-6606-468c-c86c-73b0f4e491a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Aplicando modelo de Árvore de decisão.\n",
        "import numpy as np\n",
        "np.random.seed(23)\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "modelo_dt = DecisionTreeRegressor()\n",
        "modelo_dt.fit(X_train,y_train)\n",
        "pred_dt = modelo_dt.predict(X_test)\n",
        "print(mean_squared_error(y_test,pred_dt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4211.395017927171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3bfyYR7sLOR",
        "colab_type": "code",
        "outputId": "1d8d1d63-cab8-402f-bf76-4e586b31d34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Aplicando o modelo de Florestas aleatórias.\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "modelo_rf = RandomForestRegressor(n_estimators=100,n_jobs=1,random_state=0)\n",
        "modelo_rf.fit(X_train,y_train)\n",
        "pred_rf = modelo_rf.predict(X_test)\n",
        "print(mean_squared_error(y_test,pred_rf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2174.9722956735013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5vPsmcbvo71",
        "colab_type": "code",
        "outputId": "6495f079-8bcb-468e-f0ab-917bd8c9ddec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Aplicando o modelo de Aumento de gradiente.\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "modelo_gb = GradientBoostingRegressor()\n",
        "modelo_gb.fit(X_train,y_train)\n",
        "pred_gb = modelo_gb.predict(X_test)\n",
        "print(mean_squared_error(y_test,pred_gb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2008.0343117934049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUwlT0RwOxWU",
        "colab_type": "text"
      },
      "source": [
        "## **Atenção**: Apesar de o último modelo(GradientBoostingRegressor) ter a melhor precisão, eu submeti ao desfio o primeiro modelo(LinearRegression), pois foi o que teve melhor resultado dentre os 3 primeiros, que eram os modelos que eu conhecia. Contudo resolvi aplicar o modelo GradientBoostingRegressor, que foi usado pelo ganhador do desafio, no meu conjunto de dados para verificar sua eficiência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_w0GXhqQfrn",
        "colab_type": "code",
        "outputId": "82a4ae4c-d24c-4e61-9501-668f29750506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "minha_avaliacao = mean_squared_error(y_test,pred_lr)\n",
        "avaliacao_com_modelo_ganhador = mean_squared_error(y_test,pred_gb)\n",
        "print(f\"Minha avaliação nos dados de teste que submeti ao desafio foi de {minha_avaliacao}\")\n",
        "print(f\"A avaliação nos meus dados de teste com o modelo usado pelo ganhador do desafio foi de {avaliacao_com_modelo_ganhador}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minha avaliação nos dados de teste que submeti ao desafio foi de 2123.5300794621\n",
            "A avaliação nos meus dados de teste com o modelo usado pelo ganhador do desafio foi de 2008.0343117934049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_isOLMBxI5px",
        "colab_type": "text"
      },
      "source": [
        "Depois que você criou testou e validou seu modelo, chegou a hora de preparar seu arquivo para a submissão do resultado.\n",
        "\n",
        "No código abaixo, estamos realizando a predição das notas de **linguagem e códigos** do dataset **dados_desafioqt**. Feita a previsão, criamos um dataframe novo para a submissão, primeiro crimos a coluna **ID** e adicionamos a coluna **NU_NOTA_LC** com suas respectivas previsões (repare que nosso modelo não alterou as ordens dos ID's, mas se você utilizar algum modelo que embaralhe essa ordem certifique de colocar a previsão correta para o ID correto).\n",
        "\n",
        "Após isso, salvamos o dataframe com ´.to_csv()´ (**importante, passe o parâmetro index=False para `.to_csv()`, caso contrário nosso script não computará sua nota**) no arquivo **PREDICAO_DESAFIOQT.csv (você precisa submeter o arquivo com esse nome, caso contrário nosso script de avaliação não computará sua nota**)  e utilizamos o `files.download` para baixar o arquivo em sua máquina local.\n",
        "\n",
        "Feito tudo isso você está quase pronto para finalizar e submeter seu resultado. Você já baixou os dados, treinou e validou seu modelo, salvou sua previsão **no padrão ideal para submissão** e já está com o modelo baixado em sua máquina. Entretanto, ainda falta um detalhe: no momento de preencher o **forms** você precisa enviar seu código. Caso esteja usando os notebooks do colab siga as seguintes instruções para o download:\n",
        "\n",
        "- Clique em **File** na parte superior esquerda.\n",
        "- Depois selecione a opção **Download .ipynb** (também aceitaremos o .py caso você prefira desenvolver seu projeto em um arquivo python).\n",
        "\n",
        "\n",
        "Pronto agora é só submeter seu resultado e torcer para levar um **Nintendo Switch** para casa.\n",
        "\n",
        "Boa sorte!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrhFdf5FTm19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#atribuir ao MODELO o nome do seu melhor modelo\n",
        "from google.colab import files\n",
        "\n",
        "##MODELO = modelo_lr\n",
        "##X_desafioqt = dados_desafioqt[coluna_features].to_numpy()\n",
        "##predicao_desafioqt = MODELO.predict(X_desafioqt)\n",
        "\n",
        "\n",
        "##desafio_df = pd.DataFrame(dados_desafioqt.ID)\n",
        "##desafio_df[coluna_label] = predicao_desafioqt\n",
        "\n",
        "#NÃO TROCAR O NOME DO ARQUIVO DE SAÍDA (PREDICAO_DESAFIO)\n",
        "##desafio_df.to_csv('PREDICAO_DESAFIOQT.csv', index=False) \n",
        "##files.download('PREDICAO_DESAFIOQT.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOP6A600RG2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}